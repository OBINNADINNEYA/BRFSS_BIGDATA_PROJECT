{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddbaa07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74eb8ed5",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd976c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Data splitting and model evaluation\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    cross_val_predict,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "# Performance metrics\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    make_scorer, \n",
    "    recall_score,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "# Model imports\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Imbalanced dataset handling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e7873d",
   "metadata": {},
   "source": [
    "### MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263cd113",
   "metadata": {},
   "source": [
    "### Can perceived health be accurately predicted using dietary habits, socioeconomic indicators, lifestyle choices, and individual metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b20dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46c8853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in cleaned 2019 and 2021 Dataframes with numerical outliers removed\n",
    "model_train = pd.read_csv('mydata/MMSA2019_Cleaned_2.csv')\n",
    "model_valid = pd.read_csv('mydata/MMSA2021_Cleaned_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb884eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83666 entries, 0 to 83665\n",
      "Data columns (total 97 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   DISPCODE  83666 non-null  int64  \n",
      " 1   HHADULT   83666 non-null  float64\n",
      " 2   SEXVAR    83666 non-null  object \n",
      " 3   GENHLTH   83666 non-null  object \n",
      " 4   PHYSHLTH  83666 non-null  float64\n",
      " 5   MENTHLTH  83666 non-null  float64\n",
      " 6   _HLTHPLN  83666 non-null  object \n",
      " 7   MEDCOST1  83666 non-null  object \n",
      " 8   CHECKUP1  83666 non-null  object \n",
      " 9   CVDINFR4  83666 non-null  object \n",
      " 10  CVDCRHD4  83666 non-null  object \n",
      " 11  CVDSTRK3  83666 non-null  object \n",
      " 12  ASTHMA3   83666 non-null  object \n",
      " 13  CHCSCNCR  83666 non-null  object \n",
      " 14  CHCOCNCR  83666 non-null  object \n",
      " 15  ADDEPEV3  83666 non-null  object \n",
      " 16  CHCKDNY2  83666 non-null  object \n",
      " 17  DIABETE4  83666 non-null  object \n",
      " 18  MARITAL   83666 non-null  object \n",
      " 19  EDUCA     83666 non-null  object \n",
      " 20  RENTHOM1  83666 non-null  object \n",
      " 21  CPDEMO1B  83666 non-null  float64\n",
      " 22  VETERAN3  83666 non-null  object \n",
      " 23  EMPLOY1   83666 non-null  object \n",
      " 24  CHILDREN  83666 non-null  float64\n",
      " 25  WEIGHT2   83666 non-null  float64\n",
      " 26  HEIGHT3   83666 non-null  float64\n",
      " 27  DEAF      83666 non-null  object \n",
      " 28  BLIND     83666 non-null  object \n",
      " 29  DECIDE    83666 non-null  object \n",
      " 30  DIFFWALK  83666 non-null  object \n",
      " 31  DIFFDRES  83666 non-null  object \n",
      " 32  DIFFALON  83666 non-null  object \n",
      " 33  SMOKE100  83666 non-null  object \n",
      " 34  USENOW3   83666 non-null  object \n",
      " 35  EXERANY2  83666 non-null  object \n",
      " 36  FLUSHOT7  83666 non-null  object \n",
      " 37  PNEUVAC4  83666 non-null  object \n",
      " 38  HIVTST7   83666 non-null  object \n",
      " 39  _STSTR    83666 non-null  int64  \n",
      " 40  _IMPSEX   83666 non-null  object \n",
      " 41  _RFHLTH   83666 non-null  object \n",
      " 42  _PHYS14D  83666 non-null  object \n",
      " 43  _MENT14D  83666 non-null  object \n",
      " 44  _RFHYPE6  83666 non-null  object \n",
      " 45  _RFCHOL3  83666 non-null  object \n",
      " 46  _MICHD    83666 non-null  object \n",
      " 47  _LTASTH1  83666 non-null  object \n",
      " 48  _CASTHM1  83666 non-null  object \n",
      " 49  _ASTHMS1  83666 non-null  object \n",
      " 50  _PRACE1   83666 non-null  object \n",
      " 51  _MRACE1   83666 non-null  object \n",
      " 52  _HISPANC  83666 non-null  object \n",
      " 53  _RACE     83666 non-null  object \n",
      " 54  _RACEG21  83666 non-null  object \n",
      " 55  _RACEGR3  83666 non-null  object \n",
      " 56  _SEX      83666 non-null  object \n",
      " 57  _AGEG5YR  83666 non-null  object \n",
      " 58  _AGE65YR  83666 non-null  object \n",
      " 59  _AGE80    83666 non-null  int64  \n",
      " 60  _AGE_G    83666 non-null  object \n",
      " 61  WTKG3     83666 non-null  float64\n",
      " 62  _BMI5     83666 non-null  float64\n",
      " 63  _BMI5CAT  83666 non-null  object \n",
      " 64  _RFBMI5   83666 non-null  object \n",
      " 65  _EDUCAG   83666 non-null  object \n",
      " 66  _INCOMG1  83666 non-null  object \n",
      " 67  _SMOKER3  83666 non-null  object \n",
      " 68  _RFSMOK3  83666 non-null  object \n",
      " 69  DRNKANY5  83666 non-null  int64  \n",
      " 70  _RFBING5  83666 non-null  object \n",
      " 71  _DRNKWK1  83666 non-null  float64\n",
      " 72  _RFDRHV7  83666 non-null  object \n",
      " 73  _TOTINDA  83666 non-null  object \n",
      " 74  FTJUDA2_  83666 non-null  float64\n",
      " 75  FRUTDA2_  83666 non-null  float64\n",
      " 76  GRENDA1_  83666 non-null  float64\n",
      " 77  FRNCHDA_  83666 non-null  float64\n",
      " 78  POTADA1_  83666 non-null  float64\n",
      " 79  VEGEDA2_  83666 non-null  float64\n",
      " 80  _MISFRT1  83666 non-null  int64  \n",
      " 81  _MISVEG1  83666 non-null  int64  \n",
      " 82  _FRTRES1  83666 non-null  int64  \n",
      " 83  _VEGRES1  83666 non-null  int64  \n",
      " 84  _FRUTSU1  83666 non-null  float64\n",
      " 85  _VEGESU1  83666 non-null  float64\n",
      " 86  _FRTLT1A  83666 non-null  int64  \n",
      " 87  _VEGLT1A  83666 non-null  int64  \n",
      " 88  _FRT16A   83666 non-null  int64  \n",
      " 89  _VEG23A   83666 non-null  int64  \n",
      " 90  _FRUITE1  83666 non-null  int64  \n",
      " 91  _VEGETE1  83666 non-null  int64  \n",
      " 92  _AIDTST4  83666 non-null  object \n",
      " 93  _MMSA     83666 non-null  int64  \n",
      " 94  _MMSAWT   83666 non-null  float64\n",
      " 95  STATE     83666 non-null  object \n",
      " 96  DROCDY3_  83666 non-null  float64\n",
      "dtypes: float64(20), int64(15), object(62)\n",
      "memory usage: 61.9+ MB\n"
     ]
    }
   ],
   "source": [
    "model_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8885d291",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 104619 entries, 0 to 104618\n",
      "Data columns (total 97 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   DISPCODE  104619 non-null  int64  \n",
      " 1   HHADULT   104619 non-null  float64\n",
      " 2   SEXVAR    104619 non-null  object \n",
      " 3   GENHLTH   104619 non-null  object \n",
      " 4   PHYSHLTH  104619 non-null  float64\n",
      " 5   MENTHLTH  104619 non-null  float64\n",
      " 6   _HLTHPLN  104619 non-null  object \n",
      " 7   MEDCOST1  104619 non-null  object \n",
      " 8   CHECKUP1  104619 non-null  object \n",
      " 9   CVDINFR4  104619 non-null  object \n",
      " 10  CVDCRHD4  104619 non-null  object \n",
      " 11  CVDSTRK3  104619 non-null  object \n",
      " 12  ASTHMA3   104619 non-null  object \n",
      " 13  CHCSCNCR  104619 non-null  object \n",
      " 14  CHCOCNCR  104619 non-null  object \n",
      " 15  ADDEPEV3  104619 non-null  object \n",
      " 16  CHCKDNY2  104619 non-null  object \n",
      " 17  DIABETE4  104619 non-null  object \n",
      " 18  MARITAL   104619 non-null  object \n",
      " 19  EDUCA     104619 non-null  object \n",
      " 20  RENTHOM1  104619 non-null  object \n",
      " 21  CPDEMO1B  104619 non-null  float64\n",
      " 22  VETERAN3  104619 non-null  object \n",
      " 23  EMPLOY1   104619 non-null  object \n",
      " 24  CHILDREN  104619 non-null  float64\n",
      " 25  WEIGHT2   104619 non-null  float64\n",
      " 26  HEIGHT3   104619 non-null  float64\n",
      " 27  DEAF      104619 non-null  object \n",
      " 28  BLIND     104619 non-null  object \n",
      " 29  DECIDE    104619 non-null  object \n",
      " 30  DIFFWALK  104619 non-null  object \n",
      " 31  DIFFDRES  104619 non-null  object \n",
      " 32  DIFFALON  104619 non-null  object \n",
      " 33  SMOKE100  104619 non-null  object \n",
      " 34  USENOW3   104619 non-null  object \n",
      " 35  EXERANY2  104619 non-null  object \n",
      " 36  FLUSHOT7  104619 non-null  object \n",
      " 37  PNEUVAC4  104619 non-null  object \n",
      " 38  HIVTST7   104619 non-null  object \n",
      " 39  _STSTR    104619 non-null  int64  \n",
      " 40  _IMPSEX   104619 non-null  object \n",
      " 41  _RFHLTH   104619 non-null  object \n",
      " 42  _PHYS14D  104619 non-null  object \n",
      " 43  _MENT14D  104619 non-null  object \n",
      " 44  _RFHYPE6  104619 non-null  object \n",
      " 45  _RFCHOL3  104619 non-null  object \n",
      " 46  _MICHD    104619 non-null  object \n",
      " 47  _LTASTH1  104619 non-null  object \n",
      " 48  _CASTHM1  104619 non-null  object \n",
      " 49  _ASTHMS1  104619 non-null  object \n",
      " 50  _PRACE1   104619 non-null  object \n",
      " 51  _MRACE1   104619 non-null  object \n",
      " 52  _HISPANC  104619 non-null  object \n",
      " 53  _RACE     104619 non-null  object \n",
      " 54  _RACEG21  104619 non-null  object \n",
      " 55  _RACEGR3  104619 non-null  object \n",
      " 56  _SEX      104619 non-null  object \n",
      " 57  _AGEG5YR  104619 non-null  object \n",
      " 58  _AGE65YR  104619 non-null  object \n",
      " 59  _AGE80    104619 non-null  int64  \n",
      " 60  _AGE_G    104619 non-null  object \n",
      " 61  WTKG3     104619 non-null  float64\n",
      " 62  _BMI5     104619 non-null  float64\n",
      " 63  _BMI5CAT  104619 non-null  object \n",
      " 64  _RFBMI5   104619 non-null  object \n",
      " 65  _EDUCAG   104619 non-null  object \n",
      " 66  _INCOMG1  104619 non-null  object \n",
      " 67  _SMOKER3  104619 non-null  object \n",
      " 68  _RFSMOK3  104619 non-null  object \n",
      " 69  DRNKANY5  104619 non-null  int64  \n",
      " 70  _RFBING5  104619 non-null  object \n",
      " 71  _DRNKWK1  104619 non-null  float64\n",
      " 72  _RFDRHV7  104619 non-null  object \n",
      " 73  _TOTINDA  104619 non-null  object \n",
      " 74  FTJUDA2_  104619 non-null  float64\n",
      " 75  FRUTDA2_  104619 non-null  float64\n",
      " 76  GRENDA1_  104619 non-null  float64\n",
      " 77  FRNCHDA_  104619 non-null  float64\n",
      " 78  POTADA1_  104619 non-null  float64\n",
      " 79  VEGEDA2_  104619 non-null  float64\n",
      " 80  _MISFRT1  104619 non-null  int64  \n",
      " 81  _MISVEG1  104619 non-null  int64  \n",
      " 82  _FRTRES1  104619 non-null  int64  \n",
      " 83  _VEGRES1  104619 non-null  int64  \n",
      " 84  _FRUTSU1  104619 non-null  float64\n",
      " 85  _VEGESU1  104619 non-null  float64\n",
      " 86  _FRTLT1A  104619 non-null  int64  \n",
      " 87  _VEGLT1A  104619 non-null  int64  \n",
      " 88  _FRT16A   104619 non-null  int64  \n",
      " 89  _VEG23A   104619 non-null  int64  \n",
      " 90  _FRUITE1  104619 non-null  int64  \n",
      " 91  _VEGETE1  104619 non-null  int64  \n",
      " 92  _AIDTST4  104619 non-null  object \n",
      " 93  _MMSA     104619 non-null  int64  \n",
      " 94  _MMSAWT   104619 non-null  float64\n",
      " 95  STATE     104619 non-null  object \n",
      " 96  DROCDY3_  104619 non-null  float64\n",
      "dtypes: float64(20), int64(15), object(62)\n",
      "memory usage: 77.4+ MB\n"
     ]
    }
   ],
   "source": [
    "model_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "562b0be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='_RFHLTH', ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Balance of the Dataset (TARGET VARIABLE _RFHLTH)\n",
    "sns.set_style('darkgrid')\n",
    "sns.countplot(x=model_train['_RFHLTH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8453ec24",
   "metadata": {},
   "source": [
    "### Link to Data dictionary\n",
    "[Data Dictionary](https://github.com/OBINNADINNEYA/MY_BIGDATA_PROJECT/tree/branch_1/Questionnaires%20and%20Calculated%20variables%20(Data%20Dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f36600",
   "metadata": {},
   "source": [
    "We can see that the ratio of those who percieve their health to be good vs those who do not is 7:1 an indication of a highly imbalanced Dataset. We can apply SMOTE technique to introduced randomn samples of the lower class in order to balance out the samples for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1966a382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>HHADULT</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>CPDEMO1B</th>\n",
       "      <th>CHILDREN</th>\n",
       "      <th>WEIGHT2</th>\n",
       "      <th>HEIGHT3</th>\n",
       "      <th>_STSTR</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>...</th>\n",
       "      <th>STATE_South Carolina</th>\n",
       "      <th>STATE_South Dakota</th>\n",
       "      <th>STATE_Tennessee</th>\n",
       "      <th>STATE_Texas</th>\n",
       "      <th>STATE_Utah</th>\n",
       "      <th>STATE_Vermont</th>\n",
       "      <th>STATE_Virginia</th>\n",
       "      <th>STATE_Washington</th>\n",
       "      <th>STATE_West Virginia</th>\n",
       "      <th>STATE_Wisconsin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.7780</td>\n",
       "      <td>16049</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>3.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.8034</td>\n",
       "      <td>16049</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.7272</td>\n",
       "      <td>16049</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.8288</td>\n",
       "      <td>16039</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1100</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.9304</td>\n",
       "      <td>16049</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   DISPCODE  HHADULT  PHYSHLTH  MENTHLTH  CPDEMO1B  CHILDREN  WEIGHT2  \\\n",
       "0      1200      2.0       0.0       0.0       2.0       3.0    180.0   \n",
       "1      1200      3.0      20.0       0.0       1.0       0.0    265.0   \n",
       "2      1200      1.0       1.0       0.0       1.0       0.0    170.0   \n",
       "3      1100      2.0       0.0       0.0       1.0       4.0    280.0   \n",
       "4      1100      2.0       0.0       0.0       1.0       0.0    270.0   \n",
       "\n",
       "   HEIGHT3  _STSTR  _AGE80  ...  STATE_South Carolina  STATE_South Dakota  \\\n",
       "0   1.7780   16049      35  ...                     0                   1   \n",
       "1   1.8034   16049      42  ...                     0                   1   \n",
       "2   1.7272   16049      22  ...                     0                   1   \n",
       "3   1.8288   16039      38  ...                     0                   1   \n",
       "4   1.9304   16049      72  ...                     0                   1   \n",
       "\n",
       "   STATE_Tennessee  STATE_Texas  STATE_Utah  STATE_Vermont  STATE_Virginia  \\\n",
       "0                0            0           0              0               0   \n",
       "1                0            0           0              0               0   \n",
       "2                0            0           0              0               0   \n",
       "3                0            0           0              0               0   \n",
       "4                0            0           0              0               0   \n",
       "\n",
       "   STATE_Washington  STATE_West Virginia  STATE_Wisconsin  \n",
       "0                 0                    0                0  \n",
       "1                 0                    0                0  \n",
       "2                 0                    0                0  \n",
       "3                 0                    0                0  \n",
       "4                 0                    0                0  \n",
       "\n",
       "[5 rows x 205 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a new data frame with only dummmy categorical data and num columns \n",
    "num_cols = list(model_train.select_dtypes(exclude='object').columns)\n",
    "cat_cols = list(model_train.select_dtypes(include='object').columns)\n",
    "\n",
    "dummies_df = model_train[num_cols]\n",
    "cat_cols = list(cat_cols)\n",
    "\n",
    "for i in ['GENHLTH','_RFHLTH']:\n",
    "    cat_cols.remove(i)\n",
    "\n",
    "\n",
    "for i in cat_cols:\n",
    "    temp = pd.get_dummies(model_train[i], drop_first=True, prefix=i)\n",
    "    dummies_df = pd.concat([dummies_df, temp.astype(int)], axis=1)\n",
    "\n",
    "dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68e282c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_df.columns = dummies_df.columns.astype(str)\n",
    "model_train.columns = model_train.columns.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "846d96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019 dataset\n",
    "X = dummies_df\n",
    "y = model_train['_RFHLTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab29b1b",
   "metadata": {},
   "source": [
    "## BASE MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae11cac",
   "metadata": {},
   "source": [
    "### Base Decision Tree Model\n",
    "\n",
    "- **Grid Search:** Utilized to fine-tune model hyperparameters ensuring optimal complexity and preventing overfitting.\n",
    "- **SMOTE Application:** SMOTE is applied exclusively to the training set to address class imbalance, creating synthetic samples to present the model with a balanced class representation during training.\n",
    "- **Stratified K-Fold Cross-Validation:** Ensures each fold has a representative ratio of the target classes, improving model evaluation and maintaining robustness against class imbalance.\n",
    "\n",
    "> **Note:** Stratified K-Fold is critical for imbalanced datasets to ensure that performance metrics reflect a model's true predictive power without bias introduced by uneven class distribution across folds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eea1303",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2}\n",
      "Best score: 0.867836002001402\n",
      "Accuracy for each fold using best parameters: (0.8675580787330993, 0.8688279674310898, 0.8661287912744658, 0.8677722994173016, 0.8688928731510533)\n",
      "\n",
      "Classification Report (Test Data):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.91      0.93      0.92     14038\n",
      "  fair or poor health       0.60      0.54      0.57      2696\n",
      "\n",
      "             accuracy                           0.87     16734\n",
      "            macro avg       0.76      0.74      0.75     16734\n",
      "         weighted avg       0.86      0.87      0.87     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[13091   947]\n",
      " [ 1246  1450]]\n"
     ]
    }
   ],
   "source": [
    "#1) Base Decision Tree Model\n",
    "\n",
    "# Splitting the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#SMOTE was included in the pipeline as it has been shown to produce accuracy closer to that in the test accuracy result\n",
    "pipeline = IMBPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid:\n",
    "#limiting the max_depth of the tree to prevent overfitting\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [None,10, 20],  \n",
    "    'classifier__min_samples_split': [2, 10], \n",
    "    'classifier__min_samples_leaf': [1, 5]  \n",
    "}\n",
    "\n",
    "# Cross-validation setup\n",
    "# Speak to the hyperparameters\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "\n",
    "# GridSearch setup\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring = 'accuracy',\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fitting the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "base_dtree_pipeline = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "#Retrieve the accuracy for each of the 5 folds of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "base_tree_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "\n",
    "print(f\"Accuracy for each fold using best parameters: {base_tree_cv_folds_scores}\")\n",
    "\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = base_dtree_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "# Print classification report and confusion matrix for the test data\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, predictions))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0951d",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afab2076",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 1, 'logreg__solver': 'lbfgs'}\n",
      "Best score: 0.837656101158324\n",
      "Accuracy for each fold using best parameters: (0.8352132666019273, 0.8419362067677598, 0.83998207082026, 0.8365456447034215, 0.834603316898252)\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.95      0.84      0.89     14038\n",
      "  fair or poor health       0.49      0.79      0.60      2696\n",
      "\n",
      "             accuracy                           0.83     16734\n",
      "            macro avg       0.72      0.81      0.75     16734\n",
      "         weighted avg       0.88      0.83      0.85     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[11820  2218]\n",
      " [  572  2124]]\n"
     ]
    }
   ],
   "source": [
    "#2) Base Logistic Regression \n",
    "    #By scaling features before feeding them into a logistic regression model, \n",
    "    #you help the model to treat all features fairly, speed up the training process, \n",
    "    #and make the output (coefficients) more interpretable.\n",
    "\n",
    "    # Implementing a pipeline with cross-validation ensures proper scaling practices.\n",
    "    # Each cross-validation fold scales its data separately, avoiding the mistake of using\n",
    "    # the entire dataset's information for scaling. This prevents data leakage —\n",
    "    # a situation where information from outside the training dataset influences the model.\n",
    "    # Consequently, each validation step is conducted on data scaled within its own fold,\n",
    "    # maintaining the integrity of the process and leading to a more accurate evaluation\n",
    "    # of the model's performance.\n",
    "    \n",
    "    #Model Pipieline is prepared solely on the training set to avoid data leakage\n",
    "\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Creating a logistic regression model instance\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Creating a pipeline with SMOTE and Logistic Regression:\n",
    "pipeline = IMBPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE()),\n",
    "    ('logreg', logreg_model)\n",
    "])\n",
    "\n",
    "# Defining the parameter grid\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1],\n",
    "    'logreg__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, \n",
    "    param_grid, \n",
    "    cv=5, \n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1)\n",
    "\n",
    "# Fitting GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "base_logreg_pipeline = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "#Retrieve the accuracy for each of the 5 folds of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "base_logreg_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "print(f\"Accuracy for each fold using best parameters: {base_logreg_cv_folds_scores}\")\n",
    "\n",
    "# Predictions and evaluation using the best estimator\n",
    "y_pred = base_logreg_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d292a6a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09506ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 2, 'classifier__n_estimators': 200}\n",
      "Best score: 0.8883045350264378\n",
      "Accuracy for each fold using best parameters: (0.8901172779562262, 0.8873534025547173, 0.889137905274167, 0.8855520693261617, 0.8893620200209174)\n",
      "\n",
      "Classification Report (Test Data):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.91      0.96      0.93     14038\n",
      "  fair or poor health       0.69      0.51      0.59      2696\n",
      "\n",
      "             accuracy                           0.88     16734\n",
      "            macro avg       0.80      0.73      0.76     16734\n",
      "         weighted avg       0.88      0.88      0.88     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[13437   601]\n",
      " [ 1329  1367]]\n"
     ]
    }
   ],
   "source": [
    "#3) Base Randomn forest Model\n",
    "\n",
    "# Splitting the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Pipeline with SMOTE and Random Forest classifier\n",
    "#Model Pipieline is prepared solely on the training set to avoid data leakage\n",
    "\n",
    "pipeline = IMBPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', rf_classifier)\n",
    "])\n",
    "\n",
    "# Parameter grid for Random Forest classifier including the default parameters, to get the best parameters \n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# StratifiedKFold to maintain the class distribution within each fold for accurate representation of dataset\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning and cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "\n",
    "# Fitting the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "base_rfc_pipeline = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "#Retrieve the accuracy for each of the 5 folds of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "base_rfc_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "print(f\"Accuracy for each fold using best parameters: {base_rfc_cv_folds_scores}\")\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = base_rfc_pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix for the test data\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, predictions))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50affda9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43adf2",
   "metadata": {},
   "source": [
    "## Models with Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcde63d",
   "metadata": {},
   "source": [
    "We will be using the built in feature selector from the randomn forrest:\n",
    "    \n",
    "For our transformation, I've chosen the MinMaxScaler for numeric features and the OrdinalEncoder encoder for categorical features. In the final model, I would most likely OneHotEncode (OHE) for the categorical features, but to determine feature importance, we don't want to expand the columns with OHE; we'll get more value out of treating them as one column with ordinal encoded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94155010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8eae3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 2019 datasets #1 split the data\n",
    "X = model_train.drop(columns=['_RFHLTH','GENHLTH'])\n",
    "y = model_train['_RFHLTH']\n",
    "\n",
    "#1 Split the data into 20% test and 80% training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50698ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_trans = ColumnTransformer(transformers=\n",
    "        [('num', MinMaxScaler(), selector(dtype_exclude=\"object\")),\n",
    "        ('cat', OrdinalEncoder(), selector(dtype_include=\"object\"))],\n",
    "        remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e87256d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a random forest classifier for feature importance\n",
    "#Class weight parameter is set to balanced because this is an unbalanced dataset\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42, n_jobs=6, class_weight='balanced')\n",
    "\n",
    "pipeline = Pipeline([('prep',column_trans),\n",
    "                     ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e94323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6ba710&gt;),\n",
       "                                                 (&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6b98d0&gt;)])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=6,\n",
       "                                        random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;prep&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6ba710&gt;),\n",
       "                                                 (&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                                  &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6b98d0&gt;)])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=6,\n",
       "                                        random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">prep: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;, MinMaxScaler(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6ba710&gt;),\n",
       "                                (&#x27;cat&#x27;, OrdinalEncoder(),\n",
       "                                 &lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6b98d0&gt;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6ba710&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>&lt;sklearn.compose._column_transformer.make_column_selector object at 0x16e6b98d0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_jobs=6, random_state=42)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('num', MinMaxScaler(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x16e6ba710>),\n",
       "                                                 ('cat', OrdinalEncoder(),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x16e6b98d0>)])),\n",
       "                ('clf',\n",
       "                 RandomForestClassifier(class_weight='balanced', n_jobs=6,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2 fit the pipeline to training set only to avoid data leakage\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4de5bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cumulative Importance = 0.9999999999999998\n"
     ]
    }
   ],
   "source": [
    "feat_list = []\n",
    "\n",
    "targets = list(X.columns)\n",
    "\n",
    "total_importance = 0\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(targets, pipeline['clf'].feature_importances_):\n",
    "    feat_list.append(feature)\n",
    "    total_importance += feature[1]\n",
    "\n",
    "included_feats = []\n",
    "# Print the name and gini importance of each feature\n",
    "for feature in zip(targets, pipeline['clf'].feature_importances_):\n",
    "    if feature[1] > .008:\n",
    "        included_feats.append(feature[0])\n",
    "\n",
    "print('\\n',\"Cumulative Importance =\", total_importance)\n",
    "\n",
    "# create DataFrame using data\n",
    "df_imp = pd.DataFrame(feat_list, columns =['FEATURE', 'IMPORTANCE']).sort_values(by='IMPORTANCE', ascending=False)\n",
    "df_imp['CUMSUM'] = df_imp['IMPORTANCE'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3907585",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa483016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>IMPORTANCE</th>\n",
       "      <th>CUMSUM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEXVAR</td>\n",
       "      <td>0.110991</td>\n",
       "      <td>0.110991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>_RFSMOK3</td>\n",
       "      <td>0.090577</td>\n",
       "      <td>0.201568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>_AGE65YR</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.244503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ASTHMA3</td>\n",
       "      <td>0.028459</td>\n",
       "      <td>0.272962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PHYSHLTH</td>\n",
       "      <td>0.025639</td>\n",
       "      <td>0.298602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>CPDEMO1B</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.998799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EMPLOY1</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.999347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>DIFFDRES</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.999841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DIFFWALK</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.999941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DECIDE</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     FEATURE  IMPORTANCE    CUMSUM\n",
       "2     SEXVAR    0.110991  0.110991\n",
       "66  _RFSMOK3    0.090577  0.201568\n",
       "56  _AGE65YR    0.042935  0.244503\n",
       "11   ASTHMA3    0.028459  0.272962\n",
       "3   PHYSHLTH    0.025639  0.298602\n",
       "..       ...         ...       ...\n",
       "20  CPDEMO1B    0.000574  0.998799\n",
       "22   EMPLOY1    0.000548  0.999347\n",
       "30  DIFFDRES    0.000494  0.999841\n",
       "29  DIFFWALK    0.000100  0.999941\n",
       "28    DECIDE    0.000059  1.000000\n",
       "\n",
       "[95 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d414844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Important Features:\n",
      "['SEXVAR', 'PHYSHLTH', 'MEDCOST1', 'CHECKUP1', 'CVDINFR4', 'CVDCRHD4', 'CVDSTRK3', 'ASTHMA3', 'CHCOCNCR', 'ADDEPEV3', 'CHCKDNY2', 'DIABETE4', 'MARITAL', 'EDUCA', 'RENTHOM1', 'WEIGHT2', 'HEIGHT3', 'SMOKE100', 'USENOW3', 'EXERANY2', '_ASTHMS1', '_MRACE1', '_RACEG21', '_AGEG5YR', '_AGE65YR', '_AGE_G', '_BMI5CAT', '_RFSMOK3', 'DRNKANY5', '_RFBING5', '_VEGRES1', '_VEGESU1', '_FRT16A', '_VEG23A', '_MMSAWT', 'DROCDY3_']\n",
      "Number of Included Features = 36\n"
     ]
    }
   ],
   "source": [
    "print('Most Important Features:')\n",
    "print(included_feats)\n",
    "print('Number of Included Features =', len(included_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b25ee858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>WEIGHT2</th>\n",
       "      <th>HEIGHT3</th>\n",
       "      <th>DRNKANY5</th>\n",
       "      <th>_VEGRES1</th>\n",
       "      <th>_VEGESU1</th>\n",
       "      <th>_FRT16A</th>\n",
       "      <th>_VEG23A</th>\n",
       "      <th>_MMSAWT</th>\n",
       "      <th>DROCDY3_</th>\n",
       "      <th>SEXVAR_male</th>\n",
       "      <th>MEDCOST1_yes</th>\n",
       "      <th>CHECKUP1_2 years</th>\n",
       "      <th>CHECKUP1_5 years</th>\n",
       "      <th>CHECKUP1_&gt;5 years</th>\n",
       "      <th>CHECKUP1_never</th>\n",
       "      <th>CHECKUP1_unknown</th>\n",
       "      <th>CVDINFR4_yes</th>\n",
       "      <th>CVDCRHD4_yes</th>\n",
       "      <th>CVDSTRK3_yes</th>\n",
       "      <th>ASTHMA3_yes</th>\n",
       "      <th>CHCOCNCR_yes</th>\n",
       "      <th>ADDEPEV3_yes</th>\n",
       "      <th>CHCKDNY2_yes</th>\n",
       "      <th>DIABETE4_yes</th>\n",
       "      <th>MARITAL_living together</th>\n",
       "      <th>MARITAL_married</th>\n",
       "      <th>MARITAL_separated</th>\n",
       "      <th>MARITAL_single</th>\n",
       "      <th>MARITAL_widowed</th>\n",
       "      <th>EDUCA_12/ged</th>\n",
       "      <th>EDUCA_9-11</th>\n",
       "      <th>EDUCA_c1-3</th>\n",
       "      <th>EDUCA_cg</th>\n",
       "      <th>EDUCA_none</th>\n",
       "      <th>RENTHOM1_own</th>\n",
       "      <th>RENTHOM1_rent</th>\n",
       "      <th>SMOKE100_yes</th>\n",
       "      <th>USENOW3_never</th>\n",
       "      <th>USENOW3_somedays</th>\n",
       "      <th>EXERANY2_yes</th>\n",
       "      <th>_ASTHMS1_current</th>\n",
       "      <th>_ASTHMS1_former</th>\n",
       "      <th>_MRACE1_blackonly</th>\n",
       "      <th>_MRACE1_multiracial</th>\n",
       "      <th>_MRACE1_native american_alaskanonly</th>\n",
       "      <th>_MRACE1_native hawaiian/pacific islander</th>\n",
       "      <th>_MRACE1_otherraceonly</th>\n",
       "      <th>_MRACE1_whiteonly</th>\n",
       "      <th>_RACEG21_Non-White or Hispanic</th>\n",
       "      <th>_AGEG5YR_25-29</th>\n",
       "      <th>_AGEG5YR_30-34</th>\n",
       "      <th>_AGEG5YR_35-39</th>\n",
       "      <th>_AGEG5YR_40-44</th>\n",
       "      <th>_AGEG5YR_45-49</th>\n",
       "      <th>_AGEG5YR_50-54</th>\n",
       "      <th>_AGEG5YR_55-59</th>\n",
       "      <th>_AGEG5YR_60-64</th>\n",
       "      <th>_AGEG5YR_65-69</th>\n",
       "      <th>_AGEG5YR_70-74</th>\n",
       "      <th>_AGEG5YR_75-79</th>\n",
       "      <th>_AGEG5YR_80+</th>\n",
       "      <th>_AGE65YR_65&amp;older</th>\n",
       "      <th>_AGE_G_25-34</th>\n",
       "      <th>_AGE_G_35-44</th>\n",
       "      <th>_AGE_G_45-54</th>\n",
       "      <th>_AGE_G_55-64</th>\n",
       "      <th>_AGE_G_65&amp;older</th>\n",
       "      <th>_BMI5CAT_Obese</th>\n",
       "      <th>_BMI5CAT_Overweight</th>\n",
       "      <th>_BMI5CAT_Underweight</th>\n",
       "      <th>_RFSMOK3_yes</th>\n",
       "      <th>_RFBING5_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1.7780</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.43</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>147.703815</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>1.8034</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81.705709</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.7272</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>88.929326</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>1.8288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.414992</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1.9304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.71</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20.331805</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PHYSHLTH  WEIGHT2  HEIGHT3  DRNKANY5  _VEGRES1  _VEGESU1  _FRT16A  _VEG23A  \\\n",
       "0       0.0    180.0   1.7780         1         1      1.43        1        1   \n",
       "1      20.0    265.0   1.8034         1         1      1.72        1        1   \n",
       "2       1.0    170.0   1.7272         1         1      1.24        1        1   \n",
       "3       0.0    280.0   1.8288         1         1      2.14        1        1   \n",
       "4       0.0    270.0   1.9304         1         1      4.71        1        1   \n",
       "\n",
       "      _MMSAWT  DROCDY3_  SEXVAR_male  MEDCOST1_yes  CHECKUP1_2 years  \\\n",
       "0  147.703815  0.285714            1             0                 0   \n",
       "1   81.705709  0.233333            1             0                 0   \n",
       "2   88.929326  0.133333            1             1                 0   \n",
       "3    7.414992  0.100000            1             0                 0   \n",
       "4   20.331805  0.142857            1             0                 0   \n",
       "\n",
       "   CHECKUP1_5 years  CHECKUP1_>5 years  CHECKUP1_never  CHECKUP1_unknown  \\\n",
       "0                 0                  0               0                 0   \n",
       "1                 1                  0               0                 0   \n",
       "2                 1                  0               0                 0   \n",
       "3                 1                  0               0                 0   \n",
       "4                 0                  0               0                 0   \n",
       "\n",
       "   CVDINFR4_yes  CVDCRHD4_yes  CVDSTRK3_yes  ASTHMA3_yes  CHCOCNCR_yes  \\\n",
       "0             0             0             0            0             0   \n",
       "1             0             0             0            0             0   \n",
       "2             0             0             0            0             0   \n",
       "3             0             0             0            0             0   \n",
       "4             0             0             0            0             0   \n",
       "\n",
       "   ADDEPEV3_yes  CHCKDNY2_yes  DIABETE4_yes  MARITAL_living together  \\\n",
       "0             0             0             0                        0   \n",
       "1             0             0             1                        0   \n",
       "2             0             0             0                        0   \n",
       "3             0             0             0                        0   \n",
       "4             0             0             0                        0   \n",
       "\n",
       "   MARITAL_married  MARITAL_separated  MARITAL_single  MARITAL_widowed  \\\n",
       "0                1                  0               0                0   \n",
       "1                1                  0               0                0   \n",
       "2                0                  0               1                0   \n",
       "3                1                  0               0                0   \n",
       "4                1                  0               0                0   \n",
       "\n",
       "   EDUCA_12/ged  EDUCA_9-11  EDUCA_c1-3  EDUCA_cg  EDUCA_none  RENTHOM1_own  \\\n",
       "0             0           0           1         0           0             1   \n",
       "1             0           0           0         1           0             1   \n",
       "2             0           0           0         1           0             0   \n",
       "3             0           0           0         1           0             1   \n",
       "4             0           0           0         1           0             1   \n",
       "\n",
       "   RENTHOM1_rent  SMOKE100_yes  USENOW3_never  USENOW3_somedays  EXERANY2_yes  \\\n",
       "0              0             1              1                 0             1   \n",
       "1              0             0              0                 1             1   \n",
       "2              1             0              1                 0             1   \n",
       "3              0             0              1                 0             1   \n",
       "4              0             1              1                 0             0   \n",
       "\n",
       "   _ASTHMS1_current  _ASTHMS1_former  _MRACE1_blackonly  _MRACE1_multiracial  \\\n",
       "0                 0                0                  0                    0   \n",
       "1                 0                0                  0                    0   \n",
       "2                 0                0                  0                    0   \n",
       "3                 0                0                  0                    0   \n",
       "4                 0                0                  0                    0   \n",
       "\n",
       "   _MRACE1_native american_alaskanonly  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   _MRACE1_native hawaiian/pacific islander  _MRACE1_otherraceonly  \\\n",
       "0                                         0                      0   \n",
       "1                                         0                      0   \n",
       "2                                         0                      0   \n",
       "3                                         0                      0   \n",
       "4                                         0                      0   \n",
       "\n",
       "   _MRACE1_whiteonly  _RACEG21_Non-White or Hispanic  _AGEG5YR_25-29  \\\n",
       "0                  1                               0               0   \n",
       "1                  1                               0               0   \n",
       "2                  1                               0               0   \n",
       "3                  1                               0               0   \n",
       "4                  1                               0               0   \n",
       "\n",
       "   _AGEG5YR_30-34  _AGEG5YR_35-39  _AGEG5YR_40-44  _AGEG5YR_45-49  \\\n",
       "0               0               1               0               0   \n",
       "1               0               0               1               0   \n",
       "2               0               0               0               0   \n",
       "3               0               1               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   _AGEG5YR_50-54  _AGEG5YR_55-59  _AGEG5YR_60-64  _AGEG5YR_65-69  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "\n",
       "   _AGEG5YR_70-74  _AGEG5YR_75-79  _AGEG5YR_80+  _AGE65YR_65&older  \\\n",
       "0               0               0             0                  0   \n",
       "1               0               0             0                  0   \n",
       "2               0               0             0                  0   \n",
       "3               0               0             0                  0   \n",
       "4               1               0             0                  1   \n",
       "\n",
       "   _AGE_G_25-34  _AGE_G_35-44  _AGE_G_45-54  _AGE_G_55-64  _AGE_G_65&older  \\\n",
       "0             0             1             0             0                0   \n",
       "1             0             1             0             0                0   \n",
       "2             0             0             0             0                0   \n",
       "3             0             1             0             0                0   \n",
       "4             0             0             0             0                1   \n",
       "\n",
       "   _BMI5CAT_Obese  _BMI5CAT_Overweight  _BMI5CAT_Underweight  _RFSMOK3_yes  \\\n",
       "0               0                    0                     0             0   \n",
       "1               1                    0                     0             0   \n",
       "2               0                    0                     0             0   \n",
       "3               1                    0                     0             0   \n",
       "4               1                    0                     0             1   \n",
       "\n",
       "   _RFBING5_yes  \n",
       "0             0  \n",
       "1             1  \n",
       "2             0  \n",
       "3             1  \n",
       "4             1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a new data frame with only dummmy categorical data and num columns from selected feature list\n",
    "num_cols = list(model_train[included_feats].select_dtypes(exclude='object').columns)\n",
    "cat_cols = list(model_train[included_feats].select_dtypes(include='object').columns)\n",
    "\n",
    "dummies_df2 = model_train[num_cols]\n",
    "cat_cols = list(cat_cols)\n",
    "\n",
    "for i in cat_cols:\n",
    "    temp = pd.get_dummies(model_train[i], drop_first=True, prefix=i)\n",
    "    dummies_df2 = pd.concat([dummies_df2, temp.astype(int)], axis=1)\n",
    "\n",
    "dummies_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "439422d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining the selected columns and the target column\n",
    "X = dummies_df2\n",
    "y = model_train['_RFHLTH'] #target variable (percieved good health vs percieved bad/fair health)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f67d7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10}\n",
      "Best score: 0.8601117469911085\n",
      "Accuracy for each fold using best parameters: (0.8616568312542018, 0.8591170538582207, 0.8608994471836247, 0.8615717914238757, 0.8573136112356193)\n",
      "\n",
      "Classification Report (Test Data):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.91      0.92      0.92     14038\n",
      "  fair or poor health       0.57      0.53      0.55      2696\n",
      "\n",
      "             accuracy                           0.86     16734\n",
      "            macro avg       0.74      0.73      0.73     16734\n",
      "         weighted avg       0.86      0.86      0.86     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[12938  1100]\n",
      " [ 1266  1430]]\n"
     ]
    }
   ],
   "source": [
    "#1) Decision Tree Model With Selected features\n",
    "\n",
    "# Splitting the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#SMOTE was included in the pipeline as it has been shown to produce accuracy closer to that\n",
    "#in the test accuracy result\n",
    "#Model Pipieline is prepared solely on the training set to avoid data leakage\n",
    "pipeline = IMBPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Parameter grid:\n",
    "#limiting the max_depth of the tree to prevent overfitting\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [None,10, 20],  \n",
    "    'classifier__min_samples_split': [2, 10], \n",
    "    'classifier__min_samples_leaf': [1, 5]  \n",
    "}\n",
    "\n",
    "# Cross-validation setup\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  \n",
    "\n",
    "# GridSearch setup using accuracy as our metric and inputing the stratified cross validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy', \n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fitting the model on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "dtree_pipeline = grid_search.best_estimator_\n",
    "\n",
    "#Retrieve the accuracy for each fold of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "dtree_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "print(f\"Accuracy for each fold using best parameters: {dtree_cv_folds_scores}\")\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = dtree_pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix for the test data\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, predictions))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a71e6c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'logreg__C': 0.1, 'logreg__solver': 'lbfgs'}\n",
      "Accuracy for each fold using best parameters: (0.8316276985134833, 0.8383506386793158, 0.837143284028089, 0.8348274316450023, 0.8396832511579262)\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.95      0.84      0.89     14038\n",
      "  fair or poor health       0.49      0.77      0.59      2696\n",
      "\n",
      "             accuracy                           0.83     16734\n",
      "            macro avg       0.72      0.81      0.74     16734\n",
      "         weighted avg       0.87      0.83      0.85     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[11854  2184]\n",
      " [  631  2065]]\n"
     ]
    }
   ],
   "source": [
    "#2) Logistic Regression with Selected features\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Creating a logistic regression model instance\n",
    "logreg_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Creating a pipeline with StandardScaler, SMOTE, and Logistic Regression:\n",
    "#NB: see Note above on scaling and inputing smote and scaler in pipeline before CV to avoid overfitting and data\n",
    "#leakage\n",
    "#Model Pipieline is prepared solely on the training set to avoid data leakage\n",
    "\n",
    "pipeline = IMBPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('logreg', logreg_model)\n",
    "])\n",
    "\n",
    "# Defining the parameter grid to compare parameters for estimators\n",
    "param_grid = {\n",
    "    'logreg__C': [0.01, 0.1, 1],\n",
    "    'logreg__solver': ['lbfgs']\n",
    "}\n",
    "\n",
    "# GridSearchCV setup\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "# Fitting GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and estimator\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "logreg_pipeline = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "#Retrieve the accuracy for each fold of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "logreg_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "print(f\"Accuracy for each fold using best parameters: {logreg_cv_folds_scores}\")\n",
    "\n",
    "# Predictions and evaluation using the best estimator\n",
    "y_pred = logreg_pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cd8209b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 5, 'classifier__n_estimators': 200}\n",
      "Best score: 0.8810733291107505\n",
      "Accuracy for each fold using best parameters: (0.8819750504220513, 0.8801075670426534, 0.8823397579560736, 0.8797997908262364, 0.8811444793067383)\n",
      "\n",
      "Classification Report (Test Data):\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "Good or Better Health       0.91      0.95      0.93     14038\n",
      "  fair or poor health       0.67      0.48      0.56      2696\n",
      "\n",
      "             accuracy                           0.88     16734\n",
      "            macro avg       0.79      0.72      0.75     16734\n",
      "         weighted avg       0.87      0.88      0.87     16734\n",
      "\n",
      "---------------------------------------\n",
      "Confusion Matrix (Test Data):\n",
      " [[13384   654]\n",
      " [ 1390  1306]]\n"
     ]
    }
   ],
   "source": [
    "#3) Randomn forrest Model with Selected features\n",
    "\n",
    "# Splitting the dataset into training and testing subsets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Pipeline with SMOTE and Random Forest classifier\n",
    "pipeline = IMBPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', rf_classifier)\n",
    "])\n",
    "\n",
    "# Parameter grid for Random Forest classifier including the default parameters, to get the best parameters \n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5],\n",
    "    'classifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# StratifiedKFold to maintain the class distribution within each fold for accurate representation of dataset\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# GridSearchCV for hyperparameter tuning and cross-validation\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring='accuracy',\n",
    "    cv=stratified_kfold,\n",
    "    n_jobs=-1  \n",
    ")\n",
    "\n",
    "\n",
    "# Fitting the model on the training data Only to avoid any data leakage\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best score: {grid_search.best_score_}\")\n",
    "rfc_pipeline = grid_search.best_estimator_\n",
    "\n",
    "#Retrieve the accuracy for each fold of cross-validation\n",
    "best_params_index = grid_search.best_index_\n",
    "rfc_cv_folds_scores = grid_search.cv_results_['split0_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split1_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split2_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split3_test_score'][best_params_index], \\\n",
    "                  grid_search.cv_results_['split4_test_score'][best_params_index]\n",
    "print(f\"Accuracy for each fold using best parameters: {rfc_cv_folds_scores}\")\n",
    "\n",
    "# Making predictions on the test set\n",
    "predictions = rfc_pipeline.predict(X_test)\n",
    "\n",
    "# Print classification report and confusion matrix for the test data\n",
    "print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, predictions))\n",
    "print('---------------------------------------')\n",
    "print(\"Confusion Matrix (Test Data):\\n\", confusion_matrix(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3fb30",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487b8c33",
   "metadata": {},
   "source": [
    "### WILCOXON RANKED SIGN STATISTICAL TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "673565f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Wilcoxon Test: WilcoxonResult(statistic=0.0, pvalue=0.0625)\n",
      "Random Forest Wilcoxon Test: WilcoxonResult(statistic=0.0, pvalue=0.0625)\n",
      "Logistic Regression Wilcoxon Test: WilcoxonResult(statistic=5.0, pvalue=0.625)\n"
     ]
    }
   ],
   "source": [
    "#Each test will be between the baseline and feature-selected model of the same type \n",
    "\n",
    "# Perform the Wilcoxon signed-rank test\n",
    "dtree_wilcoxon = wilcoxon(base_tree_cv_folds_scores, dtree_cv_folds_scores)\n",
    "rfc_wilcoxon = wilcoxon(base_rfc_cv_folds_scores, rfc_cv_folds_scores)\n",
    "logreg_wilcoxon = wilcoxon(base_logreg_cv_folds_scores, logreg_cv_folds_scores)\n",
    "\n",
    "# Print the test statistics and p-values\n",
    "print('Decision Tree Wilcoxon Test:', dtree_wilcoxon)\n",
    "print('Random Forest Wilcoxon Test:', rfc_wilcoxon)\n",
    "print('Logistic Regression Wilcoxon Test:', logreg_wilcoxon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ccf07e",
   "metadata": {},
   "source": [
    "### Analysis of the Wilcoxon Signed-Rank Test\n",
    "\n",
    "For the comparison of baseline models versus feature-selected models, the Wilcoxon signed-rank test was employed for each pair due to the non-parametric nature of the data and the small sample size of the cross-validation folds.\n",
    "\n",
    "#### Hypotheses:\n",
    "\n",
    "- **Null Hypotheses (H₀)**:\n",
    "  1. There is no difference in the mean ranks of accuracy scores between the baseline Decision Tree and the feature-selected Decision Tree.\n",
    "  2. There is no difference in the mean ranks of accuracy scores between the baseline Random Forest and the feature-selected Random Forest.\n",
    "  3. There is no difference in the mean ranks of accuracy scores between the baseline Logistic Regression and the feature-selected Logistic Regression.\n",
    "\n",
    "- **Alternative Hypotheses (H₁)**:\n",
    "  1. There is a difference in the mean ranks of accuracy scores between the baseline Decision Tree and the feature-selected Decision Tree.\n",
    "  2. There is a difference in the mean ranks of accuracy scores between the baseline Random Forest and the feature-selected Random Forest.\n",
    "  3. There is a difference in the mean ranks of accuracy scores between the baseline Logistic Regression and the feature-selected Logistic Regression.\n",
    "\n",
    "#### Confidence Interval: 95%\n",
    "\n",
    "#### Test Results:\n",
    "\n",
    "- **Decision Tree Comparison**:\n",
    "  - p-value = 0.0625\n",
    "  - Since the p-value is greater than 0.05, we fail to reject the null hypothesis. This suggests that there is not a statistically significant difference in mean ranks of accuracy scores between the baseline and feature-selected Decision Tree at the 95% confidence level.\n",
    "\n",
    "- **Random Forest Comparison**:\n",
    "  - p-value = 0.0625\n",
    "  - As with the Decision Tree comparison, the p-value is greater than 0.05, leading us to fail to reject the null hypothesis. There is not a statistically significant difference in mean ranks of accuracy scores between the baseline and feature-selected Random Forest at the 95% confidence level.\n",
    "\n",
    "- **Logistic Regression Comparison**:\n",
    "  - p-value = 0.625\n",
    "  - The p-value greatly exceeds the 0.05 threshold, indicating a strong likelihood that we fail to reject the null hypothesis. There is no statistically significant difference in mean ranks of accuracy scores between the baseline and feature-selected Logistic Regression models.\n",
    "\n",
    "Based on these results, none of the feature-selected models demonstrated a statistically significant improvement over the baseline models in terms of accuracy scores using the Wilcoxon signed-rank test at the 95% confidence level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278efa4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854a655",
   "metadata": {},
   "source": [
    "### SELECTION OF THE BEST MODEL FOR VALIDATION ON THE 2021 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5057fc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note Dta leakage was avoided by using two seprate datasets for \n",
    "#training and evaluation of models before validating selected model\n",
    "\n",
    "import joblib\n",
    "\n",
    "# Save the best_pipeline to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(#pipelinename, filename)\n",
    "\n",
    "# Load the model from disk later to make new predictions\n",
    "loaded_model = joblib.load(filename)\n",
    "new_data = # new data to predict in expected shape depending on the model\n",
    "new_predictions = loaded_model.predict(new_data)\n",
    "\n",
    "\n",
    "# Assuming X_2021 and y_2021 are your 2021 dataset\n",
    "# test_score = roc_auc_score(y_2021, grid_search.predict(X_2021))\n",
    "# print(f'Test score on 2021 data: {test_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b8f691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99be611",
   "metadata": {},
   "outputs": [],
   "source": [
    "####Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaa4e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49ab4f2a",
   "metadata": {},
   "source": [
    "# Reducing False Negatives in Health Predictions: A Crucial Goal\n",
    "\n",
    "**Ensuring Patient Safety**: Avoiding missed diagnoses that could lead to worsened health or preventable deaths is paramount for patient safety.\n",
    "\n",
    "**Facilitating Early Intervention**: Accurate identification of poor health allows for timely intervention, often resulting in better health outcomes.\n",
    "\n",
    "**Lowering Healthcare Costs**: Early detection of health issues can prevent the need for more complex and expensive treatments later on.\n",
    "\n",
    "**Improving Public Health**: Correct health status predictions are vital for efficient public health planning and resource allocation.\n",
    "\n",
    "**Prioritizing Healthcare Needs**: With finite resources, identifying at-risk individuals ensures that care is directed where it's most needed, such as during health crises.\n",
    "\n",
    "**Encouraging Treatment Adherence**: Patients who understand their health risks are more likely to follow treatment plans.\n",
    "\n",
    "**Maintaining Trust**: Accurate predictions reinforce trust in the healthcare system, crucial for public cooperation in health programs.\n",
    "\n",
    "In short, minimizing false negatives is essential for a trustworthy, cost-effective, and proactive healthcare system that truly serves its patients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69763b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
