{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "664b2e69",
   "metadata": {},
   "source": [
    "!pip install pydantic\n",
    "!pip install PyYAML\n",
    "!pip install jinja2\n",
    "!pip install visions\n",
    "!pip install htmlmin\n",
    "!pip install phik\n",
    "!pip install requests\n",
    "!pip install tqdm\n",
    "!pip install seaborn\n",
    "!pip install multimethod\n",
    "!pip install statsmodels\n",
    "!pip install typeguard\n",
    "!pip install imagehash\n",
    "!pip install wordcloud\n",
    "!pip install dacite\n",
    "!pip install numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35d465c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac36da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26078cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb39a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d738c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldf2019 = pd.read_csv('mydata/MMSA2019_train.csv')\n",
    "modeldf2021 = pd.read_csv('mydata/MMSA2021_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca4d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e66f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_info_columns', 1000)\n",
    "pd.set_option('display.max_info_rows', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa194659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "buffer = io.StringIO()\n",
    "modeldf2019.info(buf=buffer)\n",
    "info_str = buffer.getvalue()\n",
    "print(info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8100374",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "buffer = io.StringIO()\n",
    "modeldf2021.info(buf=buffer)\n",
    "info_str = buffer.getvalue()\n",
    "print(info_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing values of extra columns with current categorical values to keep ratio randomnly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e67cba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a42b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65fadf75",
   "metadata": {},
   "source": [
    "### Merging 2019 and 2021 BRFSS Dataframes Using Columns of Interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3275a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Any variable with value counts below 14 with be turned to a categorical nominal datatype:\n",
    "# Convert 'col1' from float to categorical\n",
    "for col in modeldf2019.columns:\n",
    "    if len(modeldf2019[col].value_counts()) < 15:\n",
    "        modeldf2019[col] = modeldf2019[col].astype('category')\n",
    "        \n",
    "for col in modeldf2021.columns:\n",
    "    if len(modeldf2021[col].value_counts()) < 15:\n",
    "        modeldf2021[col] = modeldf2021[col].astype('category')\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d88286",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extract state from MMSANAME\n",
    "def get_state(col):\n",
    "    return col.split(',')[1]\n",
    "\n",
    "modeldf2019['STATE'] = modeldf2019['MMSANAME'].apply(get_state)\n",
    "modeldf2021['STATE'] = modeldf2021['MMSANAME'].apply(get_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c56b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['FRNCHDA_','POTADA1_', 'FRUTDA2_', 'FTJUDA2_', 'VEGEDA2_', 'GRENDA1_', \n",
    "                '_FRUTSU1', '_VEGESU1', '_HLTHPLN','PRIMINSR', '_RACE', 'MEDCOST1', 'MARITAL', '_EDUCAG', \n",
    "                'RENTHOM1', 'EMPLOY1', 'CHILDREN', '_INCOMG1', '_TOTINDA', 'CHCOCNCR', 'SMOKE100', \n",
    "                'SMOKDAY2', 'USENOW3','_SMOKER3', '_RFSMOK3','_RFBING5', 'DIABETE4','EXERANY2', \n",
    "                'CHCOCNCR', '_MICHD', '_RFHYPE6', '_RFCHOL3', 'ADDEPEV3', 'DECIDE','_AGE65YR', \n",
    "                'WTKG3', '_BMI5', '_BMI5CAT', '_SEX','STATE','SEQNO','_RFHLTH']\n",
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f902a676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RENAME COLUMNS in 2019 dataset to match 2021:\n",
    "modeldf2019.rename(columns={'_INCOMG':'_INCOMG1','_RFHYPE5':'_RFHYPE6','HLTHPLN1': 'PRIMINSR','MEDCOST':'MEDCOST1',\n",
    "                  '_RFCHOL2':'_RFCHOL3'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102d6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a _HLTHPLN from PRIMINSR IN 2019 df (- '_HLTHPLN' - Categorical variable for healthcare plan )\n",
    "\n",
    "modeldf2019['_HLTHPLN'] = modeldf2019['PRIMINSR'].apply(lambda x: 1 if x in [1,2,3,4,5,6,7,8,9] \n",
    "                                                        else 2 if x == 88 else 'NA')\n",
    "\n",
    "modeldf2019['_TOTINDA'] = modeldf2019['_TOTINDA'].astype(float)\n",
    "\n",
    "#Create a DROCDY3_ from ALCDAY5 by dividing the ALCDAY5 variable by 7 days per week or 30 days per month\n",
    "def compute_drocdy3_(x):\n",
    "    # Handle NaN values\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    x_int = int(str(x).split(\".\")[0])\n",
    "    \n",
    "    if x_int == 888:\n",
    "        return 0.0\n",
    "    elif x_int // 100 == 1:\n",
    "        return (x_int % 100) / 7.0\n",
    "    elif x_int // 100 == 2:\n",
    "        return (x_int % 100) / 30.0\n",
    "    elif x_int in [777, 999]:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return float(x_int)\n",
    "\n",
    "modeldf2019['DROCDY3_'] = modeldf2019['ALCDAY5'].apply(compute_drocdy3_)\n",
    "modeldf2021['DROCDY3_'] = modeldf2021['ALCDAY5'].apply(compute_drocdy3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33ba07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get common columns\n",
    "common_columns = modeldf2019.columns.intersection(modeldf2021.columns)\n",
    "\n",
    "# Concatenate DataFrames based on common columns\n",
    "brfss_df = pd.concat([modeldf2019[common_columns], modeldf2021[common_columns]],ignore_index=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deeed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert appropriate columns into categories\n",
    "# List of columns to convert\n",
    "columns_list = ['_AGE65YR', '_INCOMG1', '_TOTINDA', '_HLTHPLN', '_RFBING5', \n",
    "                'PRIMINSR', '_EDUCAG', '_SMOKER3','_RFSMOK3','_SEX', '_RFHYPE6','PHYSHLTH',\n",
    "                '_RFHLTH','MENTHLTH','_AGEG5YR','_ASTHMS1','_HISPANC','ALCDAY5']\n",
    "\n",
    "# Convert each column to category data type in place\n",
    "for col in columns_list:\n",
    "    brfss_df[col] = brfss_df[col].astype('category')\n",
    "\n",
    "#convert height to height in meters\n",
    "def calculate_htinm(height3):\n",
    "    if 300 <= height3 <= 311:\n",
    "        htinm = ((height3 - 300) + 36)*0.0254\n",
    "    elif 400 <= height3 <= 411:\n",
    "        htinm = ((height3 - 400) + 48)*0.0254\n",
    "    elif 500 <= height3 <= 511:\n",
    "        htinm = ((height3 - 500) + 60)*0.0254\n",
    "    elif 600 <= height3 <= 611:\n",
    "        htinm = ((height3 - 600) + 72)*0.0254\n",
    "    elif 700 <= height3 <= 711:\n",
    "        htinm = ((height3 - 700) + 84)*0.0254\n",
    "    else:\n",
    "        htinm = None  # Handle cases that don't match any condition\n",
    "    \n",
    "    return htinm\n",
    "\n",
    "brfss_df['HEIGHT3'] = brfss_df['HEIGHT3'].apply(calculate_htinm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58028b03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "brfss_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96213530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets make a copy of the merged dataframe\n",
    "processed_features_df = brfss_df.copy()\n",
    "\n",
    "#Place decimal place in fruit and vegetable columns (as it was implied)\n",
    "def convert_decimal(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x/100\n",
    "    \n",
    "cols = ['FRNCHDA_','POTADA1_', 'FRUTDA2_', 'FTJUDA2_', 'VEGEDA2_', 'GRENDA1_', \n",
    "                '_FRUTSU1', '_VEGESU1','WTKG3','_BMI5']\n",
    "\n",
    "#Convert features to appropriate values by placing the decimal place \n",
    "for col in cols:\n",
    "    processed_features_df[col] = processed_features_df[col].apply(convert_decimal)\n",
    "    \n",
    "#Convert STATE column to US state\n",
    "from States import states\n",
    "processed_features_df['STATE'] = processed_features_df['STATE'].apply(lambda x: states[(x[-2:])] \n",
    "                                                                      if (x[-2:]) in states else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3fc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(processed_features_df['STATE'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa132dd",
   "metadata": {},
   "source": [
    "### Generate EDA Report with Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a385f8c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#profile = ProfileReport(modeldf2019)\n",
    "#profile.to_file(output_file=\"mydata/EDA_Report_2019.html\")\n",
    "\n",
    "#profile = ProfileReport(modeldf2021)\n",
    "#profile.to_file(output_file=\"mydata/EDA_Report_2021.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cffaabf",
   "metadata": {},
   "source": [
    "### Data Cleaning Handle Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57eb3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.reset_option('display.max_rows',None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a5fa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#check missing values in train dataset\n",
    "total = processed_features_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (processed_features_df.isnull().sum()/processed_features_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "print(missing_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3b4f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Drop columns with more that 45% missing values \n",
    "col_more45 = list(missing_data.index[missing_data['Percent'] > 0.45])\n",
    "col_more45\n",
    "processed_features_df.drop(columns=col_more45,inplace=True)\n",
    "\n",
    "#Drop columns that are of very low variance and have high unque vales and may be of no importance to ones health\n",
    "\n",
    "processed_features_df.drop(columns=['SAFETIME','CELLSEX','DISPCODE','_MMSA','_MMSAWT'],inplace=True)\n",
    "processed_features_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b23b3",
   "metadata": {},
   "source": [
    "##### Vegetable and fruit columns calculated from other veg_fruit columns (So we will keep only these ones)\n",
    "     'FRNCHDA_'- french fry intake in time per day 2\n",
    "     'POTADA1_' - computed potatoe servings per day \n",
    "     'FRUTDA2_',- number of fruits consunmed per day \n",
    "     'FTJUDA2_'- computed fruit juice intake in times per day \n",
    "     'VEGEDA2_', - COMPUTED NUMBER OF OTHER VEGIES eaten per day - not lettuce or potatoe \n",
    "     'GRENDA1_'- Number of dark green vegetables per day Times per day  \n",
    "     'FRUTSU1', Number of Fruits consumed per day \n",
    "     'VEGESU1', Number of Vegetables consumed per day \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop redundant Columns and irreleveant columns\n",
    "processed_features_df.drop(columns=['SEQNO','_AGE80','_AGE65YR','_AGE_G','SEXVAR',\n",
    "                                    'WEIGHT2','_CASTHM1','_LTASTH1','PRIMINSR','EXERANY2','CHILDREN','EDUCA',\n",
    "                                    'ASTHMA3','SMOKE100','CPDEMO1B','_STSTR','CVDINFR4','CVDCRHD4','_RACEG21'\n",
    "                                   ,'_RACEGR3','_PRACE1','_MRACE1','_IMPSEX','CADULT1','GENHLTH',\n",
    "                                    'HHADULT','_RFBMI5','VEGETAB2','POTATOE1','FRENCHF1',\n",
    "                                    'FVGREEN1','FRUITJU2','FRUIT2','HIVTST7'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096edbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vizualize misisng values using a heatmap\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(processed_features_df.isnull(),yticklabels=False,cmap='viridis',cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48314920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows where columns have less than 5% missing values \n",
    "#list of columns with less than 5% missing data \n",
    "\n",
    "#check missing values in train dataset\n",
    "total = processed_features_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (processed_features_df.isnull().sum()/processed_features_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "col_less5miss = list(missing_data.index[missing_data['Percent'] < 0.05])\n",
    "processed_features_df.dropna(subset=col_less5miss,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bd45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(missing_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d054a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing values in height with the mean for males and mean for females as it is normally distributed \n",
    "\n",
    "# Calculate mean height values for men and women separately\n",
    "mean_height_men = processed_features_df[processed_features_df['_SEX'] == 1]['HEIGHT3'].mean()\n",
    "mean_height_women = processed_features_df[processed_features_df['_SEX'] == 2]['HEIGHT3'].mean()\n",
    "\n",
    "# Replace missing values with the corresponding mean height value\n",
    "processed_features_df.loc[(processed_features_df['_SEX'] == 1) & (processed_features_df['HEIGHT3'].isnull()), 'HEIGHT3'] = mean_height_men\n",
    "processed_features_df.loc[(processed_features_df['_SEX'] == 2) & (processed_features_df['HEIGHT3'].isnull()), 'HEIGHT3'] = mean_height_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c360dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace the missing values in weight with the mean for males and mean for females as it is normally distributed \n",
    "#'WTKG3' - Weight in KG\n",
    "\n",
    "# Calculate mean weight values for men and women separately\n",
    "mean_height_men = processed_features_df[processed_features_df['_SEX'] == 1]['WTKG3'].mean()\n",
    "mean_height_women = processed_features_df[processed_features_df['_SEX'] == 2]['WTKG3'].mean()\n",
    "\n",
    "# Replace missing values with the corresponding mean weight value\n",
    "processed_features_df.loc[(processed_features_df['_SEX'] == 1) & (processed_features_df['WTKG3'].isnull()), 'WTKG3'] = mean_height_men\n",
    "processed_features_df.loc[(processed_features_df['_SEX'] == 2) & (processed_features_df['WTKG3'].isnull()), 'WTKG3'] = mean_height_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f65870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in the missing _BMI5 values with the calculated value from weight and height \n",
    "\n",
    "# Replace missing values with the Calculated BMI value\n",
    "processed_features_df['_BMI5'].fillna(processed_features_df['WTKG3'] / processed_features_df['HEIGHT3']**2, inplace=True)\n",
    "\n",
    "#fill in the missing _BMICAT5 categories with the alotted categories based on _BMI5\n",
    "def categorize_bmi(_BMI5):\n",
    "    if 0.00 <= _BMI5 < 18.50:\n",
    "        return 1\n",
    "    elif 18.50 <= _BMI5 < 25.00:\n",
    "        return 2\n",
    "    elif 25.00 <= _BMI5 < 30.00:\n",
    "        return 3\n",
    "    elif _BMI5 >= 30.00:\n",
    "        return 4\n",
    "    else:\n",
    "        return None  # Handle other possible cases (e.g. negative BMI or None)\n",
    "\n",
    "processed_features_df['_BMI5CAT']= processed_features_df['_BMI5'].apply(categorize_bmi)\n",
    "processed_features_df['_BMI5CAT'] = processed_features_df['_BMI5CAT'].astype('category')\n",
    "processed_features_df.drop(columns='_BMI5',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ef21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop rows where these columns are null\n",
    "column_names = [\n",
    "    \"MENTHLTH\",\n",
    "    \"ADDEPEV3\",\n",
    "    \"CHECKUP1\",\n",
    "    \"CVDSTRK3\",\n",
    "    \"DIABETE4\",\n",
    "    \"_HLTHPLN\",\n",
    "    \"MEDCOST1\",\n",
    "    \"CHCSCNCR\",\n",
    "    \"CHCOCNCR\",\n",
    "    \"CHCKDNY2\",\n",
    "    \"_RACE\"\n",
    "]\n",
    "processed_features_df.dropna(subset=column_names,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29068d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#check missing values in train dataset\n",
    "total = processed_features_df.isnull().sum().sort_values(ascending=False)\n",
    "percent = (processed_features_df.isnull().sum()/processed_features_df.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "#print(missing_data.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4923dce0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Replace missing fruit and vegetable column values with the median value for each race & Age category assuming that\n",
    "#different races and ages tend to have different diets\n",
    "fruit_veg_columns = [\n",
    "    '_VEGESU1',\n",
    "    '_FRUTSU1',\n",
    "    'VEGEDA2_',\n",
    "    'POTADA1_',\n",
    "    'FRNCHDA_',\n",
    "    'FTJUDA2_',\n",
    "    'GRENDA1_',\n",
    "    'FRUTDA2_']\n",
    "\n",
    "for col in fruit_veg_columns:\n",
    "    medians = processed_features_df.groupby(['_RACE', '_AGEG5YR'])[col].transform('median')\n",
    "    processed_features_df[col].fillna(medians, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a805ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The missing values in _RFCHOL3 are filled in a way that preserves the ratio of its subcategories. \n",
    "#This can be useful if you believe that the observed distribution is representative and want \n",
    "#the filled values to reflect that same distribution.\n",
    "\n",
    "# Find distribution of non-missing values\n",
    "value_counts = processed_features_df['_RFCHOL3'].value_counts(normalize=True)\n",
    "\n",
    "# Fill missing values by sampling based on this distribution\n",
    "missing_count = processed_features_df['_RFCHOL3'].isna().sum()\n",
    "if missing_count > 0:\n",
    "    imputed_values = np.random.choice(value_counts.index, \n",
    "                                      p=value_counts.values, \n",
    "                                      size=missing_count)\n",
    "    processed_features_df.loc[processed_features_df['_RFCHOL3'].isna(), '_RFCHOL3'] = imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79754bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop all rows with any NA values \n",
    "processed_features_df.dropna(inplace=True)\n",
    "#processed_features_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d5117f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vizualize misisng values using a heatmap\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(processed_features_df.isnull(),yticklabels=False,cmap='viridis',cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0670121",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Lets Generate A profile report of the cleaned data\n",
    "#profile = ProfileReport(processed_features_df,minimal=True,dark_mode=True)\n",
    "#profile.to_file(output_file=\"EDA_Report_Cleaned.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45952aab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "processed_features_df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c25044",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = processed_features_df.select_dtypes(include='float').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a87aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chesk for correlation between the numeric vairbales \n",
    "plt.figure(figsize=(12,8))\n",
    "plt.figure(figsize=(22,22))\n",
    "sns.heatmap(processed_features_df[num_cols].corr(),cmap='RdYlGn',annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a079f883",
   "metadata": {},
   "source": [
    "##### We can see the presence of significant multicolinearity between the fruits and vegetable columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cac6be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
